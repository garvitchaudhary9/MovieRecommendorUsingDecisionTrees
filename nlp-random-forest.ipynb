{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d057f995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T20:03:35.534173Z",
     "iopub.status.busy": "2021-10-13T20:03:35.533656Z",
     "iopub.status.idle": "2021-10-13T20:03:37.150532Z",
     "shell.execute_reply": "2021-10-13T20:03:37.150895Z",
     "shell.execute_reply.started": "2021-10-13T20:02:03.026366Z"
    },
    "papermill": {
     "duration": 1.640196,
     "end_time": "2021-10-13T20:03:37.151143",
     "exception": false,
     "start_time": "2021-10-13T20:03:35.510947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "from bs4 import BeautifulSoup   \n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3727cc9",
   "metadata": {
    "papermill": {
     "duration": 0.008269,
     "end_time": "2021-10-13T20:03:37.168328",
     "exception": false,
     "start_time": "2021-10-13T20:03:37.160059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Training And Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab1eb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T20:03:37.189557Z",
     "iopub.status.busy": "2021-10-13T20:03:37.189103Z",
     "iopub.status.idle": "2021-10-13T20:03:39.300269Z",
     "shell.execute_reply": "2021-10-13T20:03:39.299725Z",
     "shell.execute_reply.started": "2021-10-13T20:02:03.678894Z"
    },
    "papermill": {
     "duration": 2.123628,
     "end_time": "2021-10-13T20:03:39.300376",
     "exception": false,
     "start_time": "2021-10-13T20:03:37.176748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/garvitchaudhary/Downloads/Movie_reviewer-master/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv(\"/Users/garvitchaudhary/Downloads/Movie_reviewer-master/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35c9624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T20:03:39.330576Z",
     "iopub.status.busy": "2021-10-13T20:03:39.330117Z",
     "iopub.status.idle": "2021-10-13T20:03:39.340797Z",
     "shell.execute_reply": "2021-10-13T20:03:39.341175Z",
     "shell.execute_reply.started": "2021-10-13T20:02:05.021468Z"
    },
    "papermill": {
     "duration": 0.032001,
     "end_time": "2021-10-13T20:03:39.341301",
     "exception": false,
     "start_time": "2021-10-13T20:03:39.309300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"3453_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It seems like more consideration has gone int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"5064_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I don't believe they made this film. Complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"10905_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"10194_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"8478_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "0       \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1       \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2       \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3       \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4       \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
       "...          ...        ...                                                ...\n",
       "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
       "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
       "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
       "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
       "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a122ab1",
   "metadata": {
    "papermill": {
     "duration": 0.008617,
     "end_time": "2021-10-13T20:03:39.376761",
     "exception": false,
     "start_time": "2021-10-13T20:03:39.368144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Clearing Function\n",
    "The function clears the text from html tags and punctuation marks. Then we get a list of all words from which we delete the words that\n",
    "do not affect learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3eb288b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T20:03:39.400114Z",
     "iopub.status.busy": "2021-10-13T20:03:39.399415Z",
     "iopub.status.idle": "2021-10-13T20:03:39.401898Z",
     "shell.execute_reply": "2021-10-13T20:03:39.401321Z",
     "shell.execute_reply.started": "2021-10-13T20:02:05.297071Z"
    },
    "papermill": {
     "duration": 0.016378,
     "end_time": "2021-10-13T20:03:39.402032",
     "exception": false,
     "start_time": "2021-10-13T20:03:39.385654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    # 2. Remove non-letters     \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = letters_only.lower().split()  \n",
    "    # 4. Optionally remove stop words (false by default)                           \n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    # 5. Return a list of words\n",
    "    return( \" \".join( meaningful_words ))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbff81b",
   "metadata": {
    "papermill": {
     "duration": 0.01352,
     "end_time": "2021-10-13T20:03:39.429343",
     "exception": false,
     "start_time": "2021-10-13T20:03:39.415823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# We process all the text in the selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b49d6aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T20:03:39.465240Z",
     "iopub.status.busy": "2021-10-13T20:03:39.464628Z",
     "iopub.status.idle": "2021-10-13T20:03:53.210105Z",
     "shell.execute_reply": "2021-10-13T20:03:53.209637Z",
     "shell.execute_reply.started": "2021-10-13T20:02:53.061857Z"
    },
    "papermill": {
     "duration": 13.767399,
     "end_time": "2021-10-13T20:03:53.210253",
     "exception": false,
     "start_time": "2021-10-13T20:03:39.442854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "4.0 %\n",
      "8.0 %\n",
      "12.0 %\n",
      "16.0 %\n",
      "20.0 %\n",
      "24.0 %\n",
      "28.000000000000004 %\n",
      "32.0 %\n",
      "36.0 %\n",
      "40.0 %\n",
      "44.0 %\n",
      "48.0 %\n",
      "52.0 %\n",
      "56.00000000000001 %\n",
      "60.0 %\n",
      "64.0 %\n",
      "68.0 %\n",
      "72.0 %\n",
      "76.0 %\n",
      "80.0 %\n",
      "84.0 %\n",
      "88.0 %\n",
      "92.0 %\n",
      "96.0 %\n"
     ]
    }
   ],
   "source": [
    "# create a new list to store the clean review\n",
    "num_reviews = train[\"review\"].size\n",
    "clean_train_reviews = []\n",
    "# review_to_wordlist to clean the review and append them to the new list\n",
    "for i in range(0, num_reviews):\n",
    "    if (i%1000 == 0):\n",
    "        print(i/num_reviews * 100, '%')\n",
    "    clean_train_reviews.append(review_to_words(train[\"review\"][i] ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f6176",
   "metadata": {
    "papermill": {
     "duration": 0.015265,
     "end_time": "2021-10-13T20:03:53.243220",
     "exception": false,
     "start_time": "2021-10-13T20:03:53.227955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get the vectors of the recognitions from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6afdaf40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T20:03:53.298159Z",
     "iopub.status.busy": "2021-10-13T20:03:53.287982Z",
     "iopub.status.idle": "2021-10-13T20:03:56.303247Z",
     "shell.execute_reply": "2021-10-13T20:03:56.302807Z",
     "shell.execute_reply.started": "2021-10-13T19:50:28.442247Z"
    },
    "papermill": {
     "duration": 3.044564,
     "end_time": "2021-10-13T20:03:56.303363",
     "exception": false,
     "start_time": "2021-10-13T20:03:53.258799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initialzed a vectorizer for 20000 words\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 20000) \n",
    "#fitting the clean review data into the vectorizer\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "#converting the data to an array \n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bae000",
   "metadata": {
    "papermill": {
     "duration": 0.014905,
     "end_time": "2021-10-13T20:03:56.334073",
     "exception": false,
     "start_time": "2021-10-13T20:03:56.319168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using RandomForestClassifier as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6008aebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T20:03:56.369564Z",
     "iopub.status.busy": "2021-10-13T20:03:56.368946Z",
     "iopub.status.idle": "2021-10-13T20:05:50.073341Z",
     "shell.execute_reply": "2021-10-13T20:05:50.073834Z",
     "shell.execute_reply.started": "2021-10-13T19:50:28.443605Z"
    },
    "papermill": {
     "duration": 113.724672,
     "end_time": "2021-10-13T20:05:50.074011",
     "exception": false,
     "start_time": "2021-10-13T20:03:56.349339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#initialise a random forest with 110 trees\n",
    "forest = RandomForestClassifier(n_estimators=110) \n",
    "#fit the vectorised data into the forest along with the sentiment of clean train data\n",
    "forest = forest.fit( train_data_features, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9425bef",
   "metadata": {
    "papermill": {
     "duration": 0.022869,
     "end_time": "2021-10-13T20:05:50.120252",
     "exception": false,
     "start_time": "2021-10-13T20:05:50.097383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Outputting the result\n",
    "Let's clean up the test data and get the feature vectors from the resulting list of words. Next, we use the trained model to get the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fbe5cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T20:05:50.169254Z",
     "iopub.status.busy": "2021-10-13T20:05:50.168665Z",
     "iopub.status.idle": "2021-10-13T20:06:10.027543Z",
     "shell.execute_reply": "2021-10-13T20:06:10.027134Z",
     "shell.execute_reply.started": "2021-10-13T19:50:28.445702Z"
    },
    "papermill": {
     "duration": 19.884561,
     "end_time": "2021-10-13T20:06:10.027656",
     "exception": false,
     "start_time": "2021-10-13T20:05:50.143095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#created a  new test data list\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = [] \n",
    "#looped through all the test data reviews and use KaggleWord2Vec library to clean the data\n",
    "for i in range(0,num_reviews):\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "# vectorized the clean data and converted into an array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "#calling the random forest we created to predict the test data result\n",
    "result = forest.predict(test_data_features)\n",
    "#OUTPUT INTO CSV FILE\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 161.417412,
   "end_time": "2021-10-13T20:06:10.852583",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-13T20:03:29.435171",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
